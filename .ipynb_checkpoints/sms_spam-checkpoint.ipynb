{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3de69d2-8269-4b67-96fa-59e0526584a3",
   "metadata": {},
   "source": [
    "# SMS Spam Detection Project Overview\n",
    "### This project focused on developing a machine learning model to accurately classify SMS messages as spam (unwanted messages) or ham (legitimate messages). The goal was to enhance user experience and security by effectively identifying and filtering out spam.\n",
    "\n",
    "\n",
    "\n",
    "### In this Jupyter Notebook, a model is developed to classify email messages into two categories:\n",
    "- **Legitimate Emails (commonly referred to as 'Ham')**: These are emails that the user has explicitly or implicitly indicated they wish to receive. They include personal communications, business correspondences, and subscribed newsletters.\n",
    "- **Spam Emails (commonly known as 'Spam')**: These are unsolicited emails often sent in bulk. They range from benign advertisements to malicious emails containing scams or malware.\n",
    "\n",
    "### The goal is to accurately identify and filter out Spam emails to improve user experience and enhance security.\n",
    "\n",
    "\n",
    "## Objectives\n",
    "- Perform exploratory data analysis.\n",
    "- Prepare the dataset through preprocessing and feature engineering.\n",
    "- Build a logistic regression model to classify messages.\n",
    "- Evaluate the model using accuracy, precision, recall, and F1-score.\n",
    "- Improve the model with cross-validation and parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce4ac719-6cd6-46fa-afe1-ef8972136f1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing dependencies libraries.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eccee55-b442-452a-b25f-4e177d80b019",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset.\n",
    "spam_df = pd.read_csv('Resources/spam.csv', encoding='ISO-8859-1')\n",
    "spam_df.head() # Display DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed1608d-a44f-47fa-b709-3b0a80402cf2",
   "metadata": {},
   "source": [
    "## Initial Data Inspection\n",
    "\n",
    "### Checking number of columns, understanding the type of data each column holds, and looking for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff98fec1-767e-4a07-b05a-18869cb479a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['v1', 'v2', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review columns in dataset.\n",
    "spam_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ee0656c-ff3b-4428-81c0-5f9453c9c533",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   v1          5572 non-null   object\n",
      " 1   v2          5572 non-null   object\n",
      " 2   Unnamed: 2  50 non-null     object\n",
      " 3   Unnamed: 3  12 non-null     object\n",
      " 4   Unnamed: 4  6 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 217.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Review datatypes.\n",
    "spam_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5db6e646-5f94-4cb1-99da-6e8d0ffca411",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v1            False\n",
       "v2            False\n",
       "Unnamed: 2     True\n",
       "Unnamed: 3     True\n",
       "Unnamed: 4     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look for any null values.\n",
    "spam_df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fca24d35-8510-49e5-a002-e73d5b0aefad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v1               0\n",
       "v2               0\n",
       "Unnamed: 2    5522\n",
       "Unnamed: 3    5560\n",
       "Unnamed: 4    5566\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See total number of null values.\n",
    "spam_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04da3ce-7bef-443b-9af0-69358d2de2ce",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "### Remove unnecessary columns that mostly contain missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce83b267-468a-471d-95a5-caad1b83e668",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Cleaning: Remove unnecessary columns that mostly contain missing values.\n",
    "# Rename columns for better readability.\n",
    "spam_df = spam_df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'])\n",
    "spam_df.columns = ['Label', 'Message']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a724dffd-b274-46cd-b863-2acaf25894b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Distribution of Message Lengths by Label\n",
    "\n",
    "This visualization depicts the distribution of message lengths categorized by their labels ('spam' and 'ham')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df78e933-9b5d-43cd-9565-643a4e58d9aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exploratory Data Analysis: Adding a new column for message length.\n",
    "# Calculate the length of each message and store it in a new column in the dataframe.\n",
    "spam_df['Message Length'] = spam_df['Message'].apply(len)\n",
    "\n",
    "# Plotting the distribution of message lengths by label to visualize differences.\n",
    "plt.figure(figsize=(12, 6))  # Set the size of the plot for better visibility.\n",
    "sns.histplot(spam_df, x='Message Length', hue='Label', element='step', stat='density', common_norm=False)  # Create histogram with density instead of count to compare the distribution of 'ham' vs 'spam'.\n",
    "plt.title('Distribution of Message Lengths by Label')  # Add a title to the plot.\n",
    "plt.xlabel('Message Length')  # Label the x-axis as 'Message Length'.\n",
    "plt.ylabel('Density')  # Label the y-axis as 'Density'.\n",
    "\n",
    "plt.show()  # Display the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34577f01-9463-4a24-b6b6-079af905e08b",
   "metadata": {},
   "source": [
    "## Distribution of Spam vs Ham Messages\n",
    "\n",
    "This bar plot illustrates the count of spam versus ham messages in the dataset, providing insight into the class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63664886-5ccb-4be1-a173-7a715a8b5727",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the distribution of spam versus ham messages to visualize the imbalance.\n",
    "plt.figure(figsize=(8, 4))\n",
    "label_counts = spam_df['Label'].value_counts()\n",
    "sns.barplot(x=label_counts.index, y=label_counts.values)\n",
    "plt.title('Count of Spam vs Ham Messages')\n",
    "plt.xlabel('Label') # X axis label\n",
    "plt.ylabel('Count') # Y axis label\n",
    "plt.show() # Show bar graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e195ec58-7c5a-497b-b54b-e52e3d1e503b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature Engineering: Use TF-IDF vectorization to transform text messages into a more usable form for machine learning.\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=3000)\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(spam_df['Message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "279a59a5-6496-417e-8ff0-fa9196219690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preparing the target variable for model training.\n",
    "y = spam_df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17a5ed4a-4a30-4c7c-b1ba-738bb5336eef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets to ensure the model can be independently evaluated.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12e166f2-51d3-46e8-b85b-af879158a1da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Training: Using Logistic Regression due to its effectiveness with high-dimensional sparse data.\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ce4b726-7169-4872-a9bd-ced449a02f25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model Evaluation: Predicting the test data and evaluating accuracy and other metrics.\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1be137e6-6282-4476-b187-93f989152ad8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9509569377990431\n",
      "Confusion Matrix:\n",
      " [[1450    3]\n",
      " [  79  140]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      1.00      0.97      1453\n",
      "        spam       0.98      0.64      0.77       219\n",
      "\n",
      "    accuracy                           0.95      1672\n",
      "   macro avg       0.96      0.82      0.87      1672\n",
      "weighted avg       0.95      0.95      0.95      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print out accuracy and detailed classification metrics to assess model performance.\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65740b3-a064-4a0d-83f0-bcda31dd4bad",
   "metadata": {},
   "source": [
    "## Model Accuracy\n",
    "### This number tells us how often the model makes the right prediction about whether a message is spam or not. An accuracy of 95.1% means that about 95 times out of 100, the model's prediction is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0613c569-a44a-4d1c-b6e6-4ec1bd1cd116",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9509569377990431\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ee9263-47d5-4956-99ec-0f9774af2491",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Understanding the Confusion Matrix\n",
    "The confusion matrix helps us see the errors made by the model:\n",
    "- Top-left: Number of normal messages correctly identified.\n",
    "- Top-right: Number of normal messages wrongly identified as spam.\n",
    "- Bottom-left: Number of spam messages wrongly identified as normal.\n",
    "- Bottom-right: Number of spam messages correctly identified.\n",
    "\n",
    "For the model:\n",
    "|       | Predicted Normal | Predicted Spam |\n",
    "|-------|------------------|----------------|\n",
    "| Actual Normal | 1450               | 3              |\n",
    "| Actual Spam   | 79                 | 140            |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb3f84ee-25e4-4e4d-8952-cbeb0b0d1603",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[1450    3]\n",
      " [  79  140]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e00003-4c59-41f3-ad74-5dd0ef920eb1",
   "metadata": {},
   "source": [
    "### Detailed Performance Analysis\n",
    "The classification report gives us a deeper look at the model's performance for each type of message (normal and spam):\n",
    "- Precision: Tells us how many of the messages we predicted to be in a category were actually in that category.\n",
    "- Recall: Tells us how many of the messages that are actually in a category were predicted by us as being in that category.\n",
    "- F1-Score: Combines precision and recall into a single number that gives a better overall view of the model's effectiveness.\n",
    "\n",
    "For non-technical understanding:\n",
    "- A higher precision means when we say a message is spam, it really is spam.\n",
    "- A higher recall means we are catching a good portion of the spam messages.\n",
    "- The F1-score helps us balance precision and recall, aiming for high numbers in both.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9fc5654-5f6b-40a9-a292-375c9e248dfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      1.00      0.97      1453\n",
      "        spam       0.98      0.64      0.77       219\n",
      "\n",
      "    accuracy                           0.95      1672\n",
      "   macro avg       0.96      0.82      0.87      1672\n",
      "weighted avg       0.95      0.95      0.95      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b67bf42-b243-489b-bb73-0a0e9fe6be41",
   "metadata": {},
   "source": [
    "### Improvements (Cross-Validation and Parameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72c47753-5051-46e8-a12e-9a99de92ef22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.96950673 0.9632287  0.96319569 0.9551167  0.96409336]\n",
      "Average cross-validation score: 0.963028234214361\n",
      "Best parameters: {'C': 100, 'solver': 'liblinear'}\n",
      "Best cross-validation score: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation to evaluate the effectiveness of the Logistic Regression model\n",
    "scores = cross_val_score(LogisticRegression(max_iter=1000), X_tfidf, y, cv=5)  # Use 5-fold cross-validation to assess model stability and robustness.\n",
    "\n",
    "print(\"Cross-validation scores:\", scores)  # Print out the accuracy scores for each fold.\n",
    "print(\"Average cross-validation score:\", scores.mean())  # Calculate and print the average of these scores to get an overall idea of the model's performance.\n",
    "\n",
    "# Parameter Tuning with Grid Search to find the best model parameters.\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'solver': ['liblinear', 'lbfgs']}  # Define a grid of parameters to test.\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5, scoring='accuracy')  # Setup the grid search with 5-fold cross-validation.\n",
    "grid_search.fit(X_tfidf, y)  # Fit the grid search model.\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)  # Output the best parameters found via grid search.\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))  # Print the highest cross-validation score achieved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8a0cab-23ae-41bb-b44d-9c72fcaa91f2",
   "metadata": {},
   "source": [
    "## Model Validation and Optimization Results\n",
    "\n",
    "### Cross-Validation\n",
    "- The logistic regression model achieved the following cross-validation scores across different segments of the data: 96.9%, 96.3%, 96.3%, 95.5%, and 96.4%. \n",
    "- **Average Cross-Validation Score**: 96.3%\n",
    "  - This average score suggests that the model is robust and performs consistently across different subsets of the dataset, ensuring that it is not overfitting to a particular part of the data.\n",
    "\n",
    "### Parameter Tuning\n",
    "- **Best Parameters**: `{C: 100, solver: 'liblinear'}`\n",
    "  - `C: 100` suggests less regularization, allowing the model to capture a more complex pattern in the data without heavy penalty for larger coefficients.\n",
    "  - `solver: 'liblinear'` is an effective choice for binary classification problems, particularly on smaller or medium datasets.\n",
    "- **Best Cross-Validation Score from Grid Search**: 98%\n",
    "  - Achieving a 98% score indicates a significant improvement when these optimal parameters are used, suggesting that the model can potentially perform even better under these settings.\n",
    "\n",
    "### Next Steps\n",
    "Given the model's strong performance, let's try to further refine and utilize it through the following approaches:\n",
    "\n",
    "1. **Feature Analysis**: Investigate which features (words) most strongly influence predictions to gain insights into the model's decision-making process.\n",
    "2. **Error Analysis**: Examine specific cases where the model fails to predict correctly. This can help identify any patterns or characteristics that lead to these errors, offering clues for further improvements.\n",
    "3. **Deployment Considerations**: Explore how to implement this model in a real-world application, such as integrating it into email systems for spam detection or creating a web service for message classification.\n",
    "4. **Documentation and Reporting**: Prepare comprehensive documentation and presentations to communicate the methodology, results, and implications of this project to stakeholders or for portfolio inclusion.\n",
    "5. **Experiment with Other Models**: Test alternative modeling approaches like SVM, Random Forests, or neural networks to see if they offer improvements over the current logistic regression model.\n",
    "\n",
    "These steps will help maximize the impact and utility of the spam detection model, guiding further research and development efforts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61160c9-cd97-46a2-9337-79a2aa2f05ba",
   "metadata": {},
   "source": [
    "## Feature Analysis\n",
    "### To understand which words (features) are most influential in predicting spam, let's look at the coefficients of the logistic regression model. \n",
    "### This will show which terms have the strongest effect on classifying a message as spam or ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7188860-276b-4fe1-b8ea-2e92b32bad9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Feature  Coefficient\n",
      "2724      txt     4.267057\n",
      "1775   mobile     3.662131\n",
      "638     claim     3.385763\n",
      "2957      www     3.287982\n",
      "1033     free     3.272801\n",
      "2735       uk     3.113813\n",
      "179        50     2.977134\n",
      "2506     stop     2.943937\n",
      "2326  service     2.792092\n",
      "1851      new     2.778551\n",
      "     Feature  Coefficient\n",
      "1235     hey    -1.128683\n",
      "796      did    -1.137924\n",
      "1258    home    -1.215312\n",
      "748       da    -1.217510\n",
      "668     come    -1.268033\n",
      "1137   going    -1.279573\n",
      "1582      ll    -1.408709\n",
      "1165      gt    -1.556675\n",
      "1635      lt    -1.565242\n",
      "1895      ok    -1.638552\n"
     ]
    }
   ],
   "source": [
    "# Extracting feature names and their corresponding coefficients from the model.\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "coefficients = model.coef_[0]\n",
    "\n",
    "# Creating a DataFrame to view the features with their coefficients\n",
    "feature_importance = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefficients})\n",
    "feature_importance = feature_importance.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "# Display the top 10 features that positively influence spam detection.\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Display the top 10 features that negatively influence (more likely ham).\n",
    "print(feature_importance.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a219a9e5-bfba-4987-b977-ff8350001895",
   "metadata": {},
   "source": [
    "## Error Analysis\n",
    "By examining instances where the model fails, we can potentially uncover patterns that lead to misclassification. This involves reviewing false positives and false negatives closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5e18295-9ab7-4dd6-a1f9-2508a39f1a85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positives:\n",
      "      Actual Predicted  Spam Probability  Correct\n",
      "4700    ham      spam          0.602368    False\n",
      "3362    ham      spam          0.686462    False\n",
      "4417    ham      spam          0.686462    False\n",
      "False Negatives:\n",
      "      Actual Predicted  Spam Probability  Correct\n",
      "1044   spam       ham          0.199781    False\n",
      "683    spam       ham          0.292432    False\n",
      "4733   spam       ham          0.400106    False\n",
      "3494   spam       ham          0.452722    False\n",
      "4071   spam       ham          0.196556    False\n",
      "...     ...       ...               ...      ...\n",
      "3554   spam       ham          0.464764    False\n",
      "868    spam       ham          0.061802    False\n",
      "4346   spam       ham          0.363778    False\n",
      "2574   spam       ham          0.294162    False\n",
      "1662   spam       ham          0.262686    False\n",
      "\n",
      "[79 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities for each class for the test set.\n",
    "probabilities = model.predict_proba(X_test)\n",
    "\n",
    "# Create a DataFrame that includes the actual labels, predicted labels, and the probability of being classified as spam.\n",
    "test_results = pd.DataFrame({\n",
    "    'Actual': y_test, \n",
    "    'Predicted': y_pred, \n",
    "    'Spam Probability': probabilities[:,1]  # Slice to get probabilities of the positive class (spam).\n",
    "})\n",
    "\n",
    "# Add a new column to indicate whether the prediction was correct.\n",
    "test_results['Correct'] = test_results['Actual'] == test_results['Predicted']\n",
    "\n",
    "# Identify false positives: cases where the prediction was 'spam' but was incorrect.\n",
    "false_positives = test_results[(test_results['Predicted'] == 'spam') & (test_results['Correct'] == False)]\n",
    "\n",
    "# Identify false negatives: cases where the prediction was 'ham' but was incorrect.\n",
    "false_negatives = test_results[(test_results['Predicted'] == 'ham') & (test_results['Correct'] == False)]\n",
    "\n",
    "# Print false positives and false negatives to review these specific errors.\n",
    "print(\"False Positives:\\n\", false_positives)\n",
    "print(\"False Negatives:\\n\", false_negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91abb104-75f4-4d23-ac9e-5fc2cfb49fac",
   "metadata": {},
   "source": [
    "## Error Analysis Results\n",
    "\n",
    "In this section, I conducted an error analysis to better understand where the model is making incorrect predictions. This analysis is crucial for refining the model’s performance and enhancing its accuracy in classifying messages. I specifically focused on false positives and false negatives:\n",
    "\n",
    "### False Positives\n",
    "False positives occur when legitimate, non-spam messages are incorrectly classified as spam. This can be particularly problematic as it might lead to important communications being mistakenly filtered out, causing potential disruptions. Here are a few illustrative examples from the model:\n",
    "\n",
    "- **Message 4700**: This message was classified as spam with a probability of 60.24%, despite being a legitimate message. This indicates a possible over-sensitivity of the model to certain features.\n",
    "- **Message 3362 and 4417**: Both were classified as spam with a probability of approximately 68.65%. This high confidence level in incorrect classification suggests that the model may be overemphasizing certain words or phrases typically associated with spam.\n",
    "\n",
    "These instances demonstrate that the model might be overly aggressive in predicting spam, potentially due to common spam-associated keywords also appearing in normal communications.\n",
    "\n",
    "### False Negatives\n",
    "False negatives occur when spam messages are incorrectly labeled as non-spam, which is dangerous as it allows potentially harmful messages to bypass the filters. Some examples include:\n",
    "\n",
    "- **Messages like 1044 and 683**: These had relatively low spam probabilities (19.98% and 29.24%, respectively), indicating that the model lacked confidence in classifying these as spam.\n",
    "- **Messages 4733 through 1662**: These messages displayed a range of spam probabilities, up to 46.47%, but were not deemed spammy enough to trigger the model’s threshold.\n",
    "\n",
    "These examples highlight weaknesses in the model’s ability to detect spam, particularly when spam messages mimic legitimate messaging styles or include mixed indicators that confuse the model.\n",
    "\n",
    "### Implications\n",
    "Understanding these errors is fundamental to improving the spam detection model. By analyzing false positives, I can adjust the model to reduce its sensitivity to certain features that might lead to over-predicting spam. Conversely, by examining false negatives more closely, I can identify which features might need more emphasis in spam prediction to ensure harmful or unwanted messages are more reliably filtered out.\n",
    "\n",
    "This detailed error analysis not only aids in fine-tuning and enhancing the model but also provides deeper insights into the nature of the data and the behavior of the predictive algorithms. Going forward, I plan to conduct further analysis on a broader set of errors and integrate additional data features to help reduce both types of errors, refining the approach to spam detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faac77d-28c7-4ea2-9773-b98d0be964bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Random Forest Model\n",
    "\n",
    "In this section, the Random Forest classifier is implemented to predict whether messages are spam or not. Random Forest is an ensemble learning method that operates by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes of the individual trees. It is effective for classification tasks because it provides a higher level of accuracy by reducing overfitting and handling unbalanced datasets efficiently.\n",
    "\n",
    "We choose Random Forest for its robustness and ability to handle complex data structures with interdependencies among features, which is common in text data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b90b9be9-1450-4996-9c51-70211f62c8b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest: 0.9766746411483254\n",
      "Confusion Matrix:\n",
      " [[1449    4]\n",
      " [  35  184]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99      1453\n",
      "        spam       0.98      0.84      0.90       219\n",
      "\n",
      "    accuracy                           0.98      1672\n",
      "   macro avg       0.98      0.92      0.95      1672\n",
      "weighted avg       0.98      0.98      0.98      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary classes from sklearn for model building and evaluation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Instantiate the Random Forest classifier\n",
    "# 'n_estimators' specifies the number of trees in the forest\n",
    "# 'random_state' ensures reproducibility of your results.\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)  # Create a RandomForest with 100 decision trees to ensure model stability and reproducibility.\n",
    "\n",
    "# Train the model on the training data\n",
    "rf_model.fit(X_train, y_train)  # Fit the RandomForest model to the training data to learn from it.\n",
    "\n",
    "# Predict the labels for the test set\n",
    "rf_predictions = rf_model.predict(X_test)  # Use the trained model to make predictions on the test set.\n",
    "\n",
    "# Evaluate the model\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)  # Calculate the overall accuracy of the model on the test set.\n",
    "rf_conf_matrix = confusion_matrix(y_test, rf_predictions)  # Generate a confusion matrix to see the detailed classification results.\n",
    "rf_class_report = classification_report(y_test, rf_predictions)  # Create a comprehensive classification report showing precision, recall, and F1-scores for each class.\n",
    "\n",
    "# Display the results\n",
    "print(\"Accuracy of Random Forest:\", rf_accuracy)  # Print the accuracy of the model.\n",
    "print(\"Confusion Matrix:\\n\", rf_conf_matrix)  # Print the confusion matrix to understand the true positives, false positives, true negatives, and false negatives.\n",
    "print(\"Classification Report:\\n\", rf_class_report)  # Print the classification report to evaluate model performance for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c527290-8a70-4706-b427-8de27aaa4500",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Important Features:\n",
      "      Feature  Importance\n",
      "1033    free    0.033053\n",
      "2957     www    0.030658\n",
      "638    claim    0.030584\n",
      "1775  mobile    0.028657\n",
      "2724     txt    0.026474\n",
      "2735      uk    0.021107\n",
      "2506    stop    0.018433\n",
      "179       50    0.017743\n",
      "78      150p    0.017057\n",
      "2613    text    0.016345\n"
     ]
    }
   ],
   "source": [
    "# 'feature_importances_' attribute of the Random Forest model gives an array of importance scores\n",
    "# for all features used in the model. Each score corresponds to a feature, indicating\n",
    "# how much that feature contributes to improving the model's ability to predict the target variable.\n",
    "feature_importances = rf_model.feature_importances_\n",
    "\n",
    "# Creating a DataFrame to organize the features and their corresponding importance scores.\n",
    "# 'tfidf_vectorizer.get_feature_names_out()' gets the list of feature names which correspond to each importance score.\n",
    "features_df = pd.DataFrame({\n",
    "    'Feature': tfidf_vectorizer.get_feature_names_out(),  # Used to get an array of feature names.\n",
    "    'Importance': feature_importances  # Importance scores for each feature\n",
    "})\n",
    "\n",
    "# Sorting the DataFrame by the 'Importance' column in descending order.\n",
    "# This organizes the features starting with the most important at the top.\n",
    "features_df = features_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Displaying the top 10 most important features.\n",
    "print(\"Top 10 Important Features:\\n\", features_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c770f4-c3d5-4f5e-a638-2085a0227a7e",
   "metadata": {},
   "source": [
    "## Analysis of Top 10 Important Features\n",
    "\n",
    "The table above lists the top 10 features deemed most important by the Random Forest model for predicting whether a message is spam or not. Each feature represents a word or token, and the 'Importance' score indicates the relative contribution of each feature to the model's decision-making process. Here's a brief explanation of why these particular features might be influential:\n",
    "\n",
    "- **free**: Often used in promotional or spam messages to attract attention.\n",
    "- **www**: Common in URLs, which are frequently included in spam messages to direct users to external sites.\n",
    "- **claim**: Typically found in scam messages that involve claiming prizes or awards.\n",
    "- **mobile**: A common target in spam messages, which often offer deals or news related to mobile devices.\n",
    "- **txt**: Associated with text message services, often used in contexts requiring action like subscriptions or contests.\n",
    "- **uk**: Might appear often in region-specific promotions or spam targeting UK residents.\n",
    "- **stop**: Commonly found in opt-out instructions in unsolicited messages.\n",
    "- **50**, **150p**: These numerical features could be related to money, costs, or charges, which are frequent subjects in spam.\n",
    "- **text**: Similar to 'txt', it relates to text messaging services and can be prevalent in spam related to contests, polls, or promotions.\n",
    "\n",
    "These features have been identified by the model as the strongest predictors of spam, suggesting that messages containing these terms are more likely to be classified as spam compared to others. This insight helps us understand common characteristics of spam messages and could be used to further refine spam filtering techniques to be more effective and less intrusive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbbf14b9-ab2e-48c4-8f1c-e28ae87ca026",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.5: 0.8493150684931506, 0.45: 0.863013698630137, 0.4: 0.8767123287671232, 0.35: 0.8949771689497716, 0.3: 0.908675799086758}\n"
     ]
    }
   ],
   "source": [
    "# Import recall_score function from scikit-learn for evaluating recall\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "spam_probabilities = rf_model.predict_proba(X_test)[:, 1]  # Get the probability that each message is spam from the Random Forest model.\n",
    "\n",
    "# Function to apply different thresholds and calculate recall\n",
    "def adjust_threshold_and_calculate_recall(threshold):\n",
    "    predicted_spam = (spam_probabilities >= threshold).astype(int)  # Apply threshold to probabilities to determine binary class predictions (0 or 1).\n",
    "    recalculated_recall = recall_score(y_test == 'spam', predicted_spam)  # Calculate recall for the binary predictions against the actual spam labels.\n",
    "    return recalculated_recall  # Return the calculated recall value.\n",
    "\n",
    "# Test different thresholds\n",
    "thresholds = [0.5, 0.45, 0.4, 0.35, 0.3]  # Define a list of thresholds to test.\n",
    "recall_results = {thresh: adjust_threshold_and_calculate_recall(thresh) for thresh in thresholds}  # Dictionary comprehension to apply each threshold and store the results.\n",
    "print(recall_results)  # Print the recall results for each threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "021eb8f3-027f-44bf-9882-8f92b31800db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the TF-IDF Vectorizer with specific parameters.\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=3000, ngram_range=(1, 2))\n",
    "\n",
    "# Transform the 'Message' column into a matrix of TF-IDF features.\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(spam_df['Message'])\n",
    "\n",
    "# Split the dataset into training and testing sets, with 30% of the data used for testing.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Fit the Random Forest model to the training data.\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7bc2594-8410-42ef-a59f-c666389e6fab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Model Performance with Threshold 0.35\n",
      "Accuracy: 0.9802631578947368\n",
      "Confusion Matrix:\n",
      " [[1443   10]\n",
      " [  23  196]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.99      0.99      1453\n",
      "        spam       0.95      0.89      0.92       219\n",
      "\n",
      "    accuracy                           0.98      1672\n",
      "   macro avg       0.97      0.94      0.96      1672\n",
      "weighted avg       0.98      0.98      0.98      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the threshold to balance recall and precision\n",
    "balanced_threshold = 0.35  # Define a threshold value that has been identified as optimal for balancing recall and precision.\n",
    "\n",
    "# Compute predictions based on the adjusted threshold.\n",
    "balanced_predictions = (spam_probabilities >= balanced_threshold).astype(int)  # Create a binary outcome (0 or 1) where predictions >= 0.35 are '1' (spam).\n",
    "\n",
    "# Map integer predictions back to class labels.\n",
    "balanced_predictions_labels = np.where(balanced_predictions == 1, 'spam', 'ham')  # Convert binary outcomes to string labels 'spam' or 'ham'.\n",
    "\n",
    "# Calculate the metrics for the balanced approach.\n",
    "balanced_accuracy = accuracy_score(y_test, balanced_predictions_labels)  # Calculate accuracy to evaluate overall model performance.\n",
    "balanced_conf_matrix = confusion_matrix(y_test, balanced_predictions_labels)  # Generate confusion matrix to see the counts of TP, FP, TN, and FN.\n",
    "balanced_report = classification_report(y_test, balanced_predictions_labels)  # Generate a detailed classification report showing precision, recall, and F1-score for each class.\n",
    "\n",
    "# Output the balanced results\n",
    "print(\"Balanced Model Performance with Threshold 0.35\")  # Print a header for clarity in output.\n",
    "print(\"Accuracy:\", balanced_accuracy)  # Print the computed accuracy.\n",
    "print(\"Confusion Matrix:\\n\", balanced_conf_matrix)  # Print the confusion matrix to show actual vs predicted classifications.\n",
    "print(\"Classification Report:\\n\", balanced_report)  # Print the classification report for a detailed performance analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bb2ccd-83fb-46a4-95ed-336fab1526eb",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    " The successful implementation of this spam detection model marks a significant step towards enhancing messaging platform's security and usability.\n",
    "\n",
    "### Model Performance\n",
    "After extensive testing and optimization, the model achieved impressive performance metrics:\n",
    "- **Accuracy**: Above 98%, indicating that the model correctly identifies spam and ham messages with high reliability.\n",
    "- **Precision for Spam**: Approximately 95%, showing that when the model predicts messages as spam, they are indeed spam about 95% of the time.\n",
    "- **Recall for Spam**: Around 89%, ensuring that the model captures a significant majority of spam messages, thereby protecting users from unwanted content.\n",
    "\n",
    "### Key Achievements\n",
    "- **Balanced Approach**: The model is optimized to balance both precision and recall, ensuring that it not only identifies most spam messages but also minimizes the number of legitimate messages mistakenly classified as spam.\n",
    "- **User Experience**: By maintaining high accuracy and recall, the model contributes to a safer and more pleasant messaging environment for users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98459654-291e-44fd-9a57-560b087c7e19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
